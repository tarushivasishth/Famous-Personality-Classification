{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcc940-a551-44c8-a1af-28320c4ed930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os\n",
    "\n",
    "# API_KEY = 'AIzaSyD3mp0muKxh6-oShy-FuxgGTiOcSh7qTDI'\n",
    "# SEARCH_ENGINE_ID = '902767cb88f7e42ee'\n",
    "\n",
    "# def download_images(query, num_images=50):\n",
    "#     search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    \n",
    "#     # Parameters for search\n",
    "#     params = {\n",
    "#         'q': query,\n",
    "#         'searchType': 'image',\n",
    "#         'key': API_KEY,\n",
    "#         'cx': SEARCH_ENGINE_ID,\n",
    "#         'num': 10,  # Max 10 results per request\n",
    "#         'start': 1\n",
    "#     }\n",
    "\n",
    "#     images = []\n",
    "#     count = 0\n",
    "#     while count < num_images:\n",
    "#         res = requests.get(search_url, params=params)\n",
    "        \n",
    "#         # Print full response to see what's happening\n",
    "#         print(res.json())\n",
    "        \n",
    "#         if res.status_code == 200:\n",
    "#             data = res.json()\n",
    "            \n",
    "#             # Check if 'items' exists in response\n",
    "#             if 'items' in data:\n",
    "#                 for item in data['items']:\n",
    "#                     images.append(item['link'])\n",
    "#                     count += 1\n",
    "#                     if count >= num_images:\n",
    "#                         break\n",
    "#             else:\n",
    "#                 print(f\"No results found for query: {query}\")\n",
    "#                 break\n",
    "#         else:\n",
    "#             print(f\"Error: {res.status_code}, {res.text}\")\n",
    "#             break\n",
    "        \n",
    "#         # Update the start index for the next batch of results\n",
    "#         params['start'] += 10\n",
    "\n",
    "#     # Download and save images\n",
    "#     if images:\n",
    "#         os.makedirs('./dataset/images', exist_ok=True)\n",
    "#         for idx, img_url in enumerate(images):\n",
    "#             try:\n",
    "#                 img_data = requests.get(img_url).content\n",
    "#                 with open(f'images/image_{idx+1}.jpg', 'wb') as img_file:\n",
    "#                     img_file.write(img_data)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error downloading image {idx+1}: {e}\")\n",
    "    \n",
    "#     print(f'{len(images)} images downloaded successfully.')\n",
    "\n",
    "# # Example usage:\n",
    "# download_images('cats', 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4924c4-7086-4b00-8659-9ef4c2bdaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = 'AIzaSyD3mp0muKxh6-oShy-FuxgGTiOcSh7qTDI'\n",
    "# SEARCH_ENGINE_ID = '902767cb88f7e42ee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e662517-6868-4758-8f78-98c142b0c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429\n",
      "No more images found.\n",
      "Fetched 0 image URLs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your Custom Search API key and search engine ID\n",
    "API_KEY = 'AIzaSyD3mp0muKxh6-oShy-FuxgGTiOcSh7qTDI'\n",
    "SEARCH_ENGINE_ID = '902767cb88f7e42ee'\n",
    "query = 'Virat Kohli'\n",
    "num_images_to_fetch = 50\n",
    "\n",
    "# Function to fetch images from the API\n",
    "def fetch_images(query, start_index, num_images=10):\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&searchType=image&key={API_KEY}&cx={SEARCH_ENGINE_ID}&start={start_index}&num={num_images}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Fetch all images in batches of 10\n",
    "all_image_urls = []\n",
    "for start in range(1, num_images_to_fetch, 10):\n",
    "    json_data = fetch_images(query, start)\n",
    "    if json_data and 'items' in json_data:\n",
    "        image_urls = [item['link'] for item in json_data['items']]\n",
    "        all_image_urls.extend(image_urls)\n",
    "    else:\n",
    "        print(\"No more images found.\")\n",
    "        break\n",
    "\n",
    "print(f\"Fetched {len(all_image_urls)} image URLs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce78ba23-ee0d-41f7-9793-23e905e86219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save images\n",
    "save_dir = \"dataset/virat_kohli\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Download each image\n",
    "for i, url in enumerate(all_image_urls):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join(save_dir, f\"image_{i+1}.jpg\"), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Image {i+1} downloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to download image {i+1}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c976a6f-2712-4e30-9faa-1ec7362a304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429\n",
      "No more images found.\n",
      "Fetched 10 image URLs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your Custom Search API key and search engine ID\n",
    "API_KEY = 'AIzaSyD3mp0muKxh6-oShy-FuxgGTiOcSh7qTDI'\n",
    "SEARCH_ENGINE_ID = '902767cb88f7e42ee'\n",
    "query = 'APJ Abdul Kalam'\n",
    "num_images_to_fetch = 50\n",
    "\n",
    "# Function to fetch images from the API\n",
    "def fetch_images(query, start_index, num_images=10):\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&searchType=image&key={API_KEY}&cx={SEARCH_ENGINE_ID}&start={start_index}&num={num_images}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Fetch all images in batches of 10\n",
    "all_image_urls = []\n",
    "for start in range(1, num_images_to_fetch, 10):\n",
    "    json_data = fetch_images(query, start)\n",
    "    if json_data and 'items' in json_data:\n",
    "        image_urls = [item['link'] for item in json_data['items']]\n",
    "        all_image_urls.extend(image_urls)\n",
    "    else:\n",
    "        print(\"No more images found.\")\n",
    "        break\n",
    "\n",
    "print(f\"Fetched {len(all_image_urls)} image URLs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839c491f-faa8-42d8-92c1-c78803457a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 downloaded successfully.\n",
      "Image 2 downloaded successfully.\n",
      "Image 3 downloaded successfully.\n",
      "Image 4 downloaded successfully.\n",
      "Image 5 downloaded successfully.\n",
      "Image 6 downloaded successfully.\n",
      "Image 7 downloaded successfully.\n",
      "Image 8 downloaded successfully.\n",
      "Image 9 downloaded successfully.\n",
      "Image 10 downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save images\n",
    "save_dir = \"dataset/abdul_kalam\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Download each image\n",
    "for i, url in enumerate(all_image_urls):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join(save_dir, f\"image_{i+1}.jpg\"), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Image {i+1} downloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to download image {i+1}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2385a59a-799a-49a1-bd0a-b6480d17de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429\n",
      "No more images found.\n",
      "Fetched 10 image URLs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your Custom Search API key and search engine ID\n",
    "API_KEY = 'AIzaSyD3mp0muKxh6-oShy-FuxgGTiOcSh7qTDI'\n",
    "SEARCH_ENGINE_ID = '902767cb88f7e42ee'\n",
    "query = 'Ratan Tata'\n",
    "num_images_to_fetch = 50\n",
    "\n",
    "# Function to fetch images from the API\n",
    "def fetch_images(query, start_index, num_images=10):\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&searchType=image&key={API_KEY}&cx={SEARCH_ENGINE_ID}&start={start_index}&num={num_images}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Fetch all images in batches of 10\n",
    "all_image_urls = []\n",
    "for start in range(1, num_images_to_fetch, 10):\n",
    "    json_data = fetch_images(query, start)\n",
    "    if json_data and 'items' in json_data:\n",
    "        image_urls = [item['link'] for item in json_data['items']]\n",
    "        all_image_urls.extend(image_urls)\n",
    "    else:\n",
    "        print(\"No more images found.\")\n",
    "        break\n",
    "\n",
    "print(f\"Fetched {len(all_image_urls)} image URLs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c30f6b89-8252-48ec-9bb2-b0c782b6017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download image 1.\n",
      "Image 2 downloaded successfully.\n",
      "Image 3 downloaded successfully.\n",
      "Image 4 downloaded successfully.\n",
      "Image 5 downloaded successfully.\n",
      "Image 6 downloaded successfully.\n",
      "Image 7 downloaded successfully.\n",
      "Image 8 downloaded successfully.\n",
      "Image 9 downloaded successfully.\n",
      "Image 10 downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save images\n",
    "save_dir = \"dataset/ratan_tata\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Download each image\n",
    "for i, url in enumerate(all_image_urls):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join(save_dir, f\"image_{i+1}.jpg\"), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Image {i+1} downloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to download image {i+1}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f80d42f-8c32-48fa-b5bc-00362e5d5bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429\n",
      "No more images found.\n",
      "Fetched 0 image URLs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your Custom Search API key and search engine ID\n",
    "API_KEY = 'AIzaSyD3mp0muKxh6-oShy-FuxgGTiOcSh7qTDI'\n",
    "SEARCH_ENGINE_ID = '902767cb88f7e42ee'\n",
    "query = 'Sheetal Devi'\n",
    "num_images_to_fetch = 50\n",
    "\n",
    "# Function to fetch images from the API\n",
    "def fetch_images(query, start_index, num_images=10):\n",
    "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&searchType=image&key={API_KEY}&cx={SEARCH_ENGINE_ID}&start={start_index}&num={num_images}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Fetch all images in batches of 10\n",
    "all_image_urls = []\n",
    "for start in range(1, num_images_to_fetch, 10):\n",
    "    json_data = fetch_images(query, start)\n",
    "    if json_data and 'items' in json_data:\n",
    "        image_urls = [item['link'] for item in json_data['items']]\n",
    "        all_image_urls.extend(image_urls)\n",
    "    else:\n",
    "        print(\"No more images found.\")\n",
    "        break\n",
    "\n",
    "print(f\"Fetched {len(all_image_urls)} image URLs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d595cff-5de1-430c-a7f7-c9a2f3c866b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save images\n",
    "save_dir = \"dataset/sheetal_devi\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Download each image\n",
    "for i, url in enumerate(all_image_urls):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join(save_dir, f\"image_{i+1}.jpg\"), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Image {i+1} downloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to download image {i+1}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef2e21-e985-426f-88a4-a807bcc94632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
